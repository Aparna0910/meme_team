{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQq8W1N2E58P"
      },
      "source": [
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3A-CWVxE_6E"
      },
      "source": [
        "## Input priocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wiRO9GWFCKx"
      },
      "source": [
        "import cv2\r\n",
        "import numpy as np\r\n",
        "from cv2 import imread\r\n",
        "from cv2 import imshow\r\n",
        "from cv2 import waitKey\r\n",
        "from cv2 import destroyAllWindows\r\n",
        "from cv2 import CascadeClassifier\r\n",
        "from cv2 import rectangle\r\n",
        "import torch\r\n",
        "from FECNet import FECNet\r\n",
        "# function to get face image from img_path\r\n",
        "\r\n",
        "def preprocess_image_face(image_path):\r\n",
        "  # load the photograph\r\n",
        "  pixels = imread(image_path)\r\n",
        "  # load the pre-trained model\r\n",
        "  classifier = CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\r\n",
        "  # perform face detection\r\n",
        "  bboxes = classifier.detectMultiScale(pixels)\r\n",
        "  # print bounding box for each detected face\r\n",
        "  for box in bboxes:\r\n",
        "\t  # extract\r\n",
        "\t  x, y, width, height = box\r\n",
        "\t  x2, y2 = x + width, y + height\r\n",
        "\t  # draw a rectangle over the pixels\r\n",
        "\t  #rectangle(pixels, (x, y), (x2, y2), (0,0,255), 1)\r\n",
        "  # show the image\r\n",
        "  #cv2_imshow(pixels)\r\n",
        "\r\n",
        "  def get_crop_of_face(bboxes, pixels):\r\n",
        "\r\n",
        "    list_width_height = list(np.sum(bboxes[:, -2:], axis = -1))\r\n",
        "    index_max_width_height = list_width_height.index(max(list_width_height))\r\n",
        "\r\n",
        "    x, y, w, h = bboxes[index_max_width_height]\r\n",
        "    x2, y2 = x + w, y + h\r\n",
        "    height, width, _ = pixels.shape\r\n",
        "    cropped_img = pixels[(y-int(0.1*height)):(y2+int(0.1*height)), (x-int(0.01*width)):(x2+int(0.01*width))]\r\n",
        "    \r\n",
        "\r\n",
        "    cropped_img = cv2.resize(cropped_img, (224, 224))\r\n",
        "    #cv2_imshow(cropped_img)\r\n",
        "    x = cropped_img.astype(np.float32).reshape(-1, 3, 224, 224)\r\n",
        "    #x = np.expand_dims(cropped_img, axis=0)\r\n",
        "    #x = preprocess_input(x)\r\n",
        "  \r\n",
        "    return x\r\n",
        "\r\n",
        "  return get_crop_of_face(bboxes, pixels)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itRnoTSrFCjt"
      },
      "source": [
        "def get_embeddings(img_path):\r\n",
        "  model = FECNet()\r\n",
        "  model.load_state_dict(torch.load('/content/drive/MyDrive/facenet model/FECNet.pt',  map_location=torch.device('cpu')))\r\n",
        "  model.eval()\r\n",
        "  image = preprocess_image_face(img_path)\r\n",
        "  #print(np.shape(image))\r\n",
        "  image = torch.from_numpy(image)\r\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "  image = image.to(device)\r\n",
        "  #image.unsqueeze_(3)\r\n",
        "  #print(image.size())\r\n",
        "  emb = model(image)\r\n",
        "  return emb"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAkzdm0sFOxN"
      },
      "source": [
        "def cosine_sim(x1, x2):\r\n",
        "  x1 = x1.cpu().detach().numpy()\r\n",
        "  x2 = x2.cpu().detach().numpy()\r\n",
        "  norm1 = (np.linalg.norm(x1))\r\n",
        "  norm2 = (np.linalg.norm(x2))\r\n",
        "  return np.dot(x1, x2.T)/(norm1*norm2)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJCAhwdwFW9f"
      },
      "source": [
        "emb1 = get_embeddings('/content/drive/MyDrive/data/t3.jpg')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4IBZVgIHdoI"
      },
      "source": [
        "emb2 = get_embeddings('/content/drive/MyDrive/data/t3.jpg')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1pQBVHhIYm3",
        "outputId": "4b16121b-7725-4e46-c567-a1eaeeba42a1"
      },
      "source": [
        "cosine_sim(emb1, emb2)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99999994]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex3ikOaPId18"
      },
      "source": [
        "def get_prediction(img_path1, img_path2):\r\n",
        "  emb1 = get_embeddings(img_path1)\r\n",
        "  emb2 = get_embeddings(img_path2)\r\n",
        "\r\n",
        "  return cosine_sim(emb1, emb2)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K93qPk8XJKfv",
        "outputId": "941626cf-ebd1-479e-9ce2-a7d3b3b9d868"
      },
      "source": [
        "get_prediction('/content/drive/MyDrive/data/t3.jpg', '/content/drive/MyDrive/data/t3.jpg')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99999994]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X--0WEvOJXYq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}