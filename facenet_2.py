# -*- coding: utf-8 -*-
"""FaceNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N2A52dCKjBLCWFrwYLG8C3cUqNgNy6LV
"""

import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import cv2
from google.colab.patches import cv2_imshow

# !unzip "/content/drive/MyDrive/data images/FEC_dataset.zip" -d "/content/drive/MyDrive/data images"

#df = pd.read_csv('/content/drive/MyDrive/data images/FEC_dataset/faceexp-comparison-data-train-public.csv', error_bad_lines=False, header=None)
df_cleaned = pd.read_csv('/content/drive/MyDrive/data images/FEC_dataset/faceexp-comparison-data-train-public_cleaned.csv', error_bad_lines=False, nrows=13000)

df_cleaned.head()

# header = ['index',
#           'link1',
#  'x11',
#  'x21',
#  'y11',
#  'y21',
#  'link2',
#  'x12',
#  'x22',
#  'y12',
#  'y22',
#  'link3',
#  'x13',
#  'x23',
#  'y13',
#  'y23',
#  'triplet type',
#  'annotator1_id',
#  'annotation1',
#  'annotator2_id',
#  'annotation2',
#  'annotator3_id',
#  'annotation3',
#  'annotator4_id',
#  'annotation4',
#  'annotator5_id',
#  'annotation5',
#  'annotator6_id',
#  'annotation6',
#  ]

# #df.columns = header
# df_cleaned.columns = header

## Importing Necessary Modules

import requests # to get image from the web
import shutil # to save it locally
import os

d = 0

for i in range(len(df)):
  flag = False
  for j in range(1, 4):
    if flag == True:
      continue
    
    image_url = df.iloc[i]['link'+str(j)]
    filename = '/content/drive/MyDrive/face images/'+'triplet'+str(d)+' img'+str(j)+'.jpg'
    # Open the url image, set stream to True, this will return the stream content.
    r = requests.get(image_url, stream = True)

  
    # Check if the image was retrieved successfully
    if r.status_code == 200:
        # Set decode_content value to True, otherwise the downloaded image file's size will be zero.
        r.raw.decode_content = True
    
        # Open a local file with wb ( write binary ) permission.
        with open(filename,'wb') as f:
            shutil.copyfileobj(r.raw, f)
        
        print('Image sucessfully Downloaded: ',filename)

    else:
        flag = True
        for k in range(1, j):
          filename = '/content/drive/MyDrive/face images/'+'triplet'+str(d)+' img'+str(k)+'.jpg'
          os.remove(filename)
          print('Image Deleted', d, k)
          
        
  
  if flag == True:
    
    df_cleaned = df_cleaned.drop(d)
    df_cleaned = df_cleaned.reset_index(drop=True)
    d = d-1
    

  d += 1

## export the cleaned df
df_cleaned.to_csv('/content/drive/MyDrive/data images/FEC_dataset/faceexp-comparison-data-train-public_cleaned.csv')

len(df_cleaned)

# ## visulaizing the triplets
# for i in range(40):
#   print()
#   print()
#   try :
#     for j in range(1, 4):
#       img = cv2.imread('/content/drive/MyDrive/face images/'+'triplet' + str(i) + ' img' + str(j)+ '.jpg')
#       x1 = df_cleaned.iloc[i]['x1'+str(j)]
#       x2 = df_cleaned.iloc[i]['x2'+str(j)] ## coordinates for face crop from image
#       y1 = df_cleaned.iloc[i]['y1'+str(j)]
#       y2 = df_cleaned.iloc[i]['y2'+str(j)]
#       height, width,channels = img.shape
#       crop = img[int(height*y1): int(height*y2), int(width*x1) : int(width*x2)]
#       crop = cv2.resize(crop, (299, 299))
#       plt.figure()
#       plt.imshow(crop)
#   except:
#     continue

def get_triplet(start, end):
  X = []
  for  i in range(start, end):
    print(i, end=' ')
     # this function will be used to iterate over triplets
    df_cleaned_i = df_cleaned.iloc[i]
    triplet = []
    for j in range(1, 4): # iterating over a triplet
      img = cv2.imread('/content/drive/MyDrive/face images/'+'triplet' + str(i) + ' img' + str(j)+ '.jpg') # reading the image
      x1 = df_cleaned_i['x1'+str(j)]
      x2 = df_cleaned_i['x2'+str(j)] ## coordinates for face crop from image
      y1 = df_cleaned_i['y1'+str(j)]
      y2 = df_cleaned_i['y2'+str(j)]

      height, width,channels = img.shape

      crop = img[int(height*y1): int(height*y2), int(width*x1) : int(width*x2)]
      crop = cv2.resize(crop, (299, 299))
      triplet.append(crop)
  
    annot = []
    for k in range(1, 7):
      annot.append(df_cleaned_i['annotation'+str(k)])

    dissimilar_img_index = int(np.median(annot))-1 # finding dissimalr image in a triplet

    #aligning the triplet in such a way that similar images occurs first then dissimilar this will help us after in triplet loss function

    triplet[2], triplet[dissimilar_img_index] = triplet[dissimilar_img_index], triplet[2] #swapping with last image

    X.append(triplet)

  return np.array(X)

X_val = get_triplet(12001, 12200)





np.shape(X_train)

for i in range(3):
  cv2_imshow(X_train[1, i]) # 2nd triplet

X_temp = X_train.reshape((90, 299, 299,3))

for i in range(3, 6): #0, 1, 2 first triplet similarly 3, 4, 5 forms second triplet
  cv2_imshow(X_temp[i])

def show_triplet(triplet):
  for image in triplet:
   cv2_imshow(image)

"""## Notice first two images have more similar expressions than the third one this will help us to generalize triplet loss function"""

from tensorflow.keras.applications import InceptionV3

inception = InceptionV3()
#densenet = DenseNet121()

inception.summary()

# layer_inputs = inception.input
# layer_outputs = [layer.output for layer in inception.layers]
# inception_features = tf.keras.models.Model(layer_inputs, layer_outputs)

model1 = tf.keras.models.Model(inception.input, inception.layers[248].output)

model1.summary()

from tensorflow.keras.models import Sequential, Model, load_model
from tensorflow.keras.layers import Dense, Conv2D, Flatten, BatchNormalization, Dropout, MaxPool2D, Input, AveragePooling2D, LayerNormalization, Concatenate

def model2():
  inputs = Input((8, 8, 1280))
  x = Conv2D(1280, (3, 3), padding = 'same', activation='relu')(inputs)
  x = Dropout(0.5)(x)
          #x = Conv2D(1280, (2, 2), padding = 'same', activation='relu')(x)
          #x = Dropout(0.25)(x)
  x = BatchNormalization()(x)
  x = Conv2D(1280, (3, 3), padding = 'same', activation='relu')(inputs)
  x = Dropout(0.5)(x)
        #x = Conv2D(1024, (2, 2), padding = 'same', activation='relu')(x)
          #x = Dropout(0.25)(x)
  x = BatchNormalization()(x)
  x = Conv2D(1280, (3, 3), padding = 'same', activation='relu')(inputs)
  x = Dropout(0.5)(x)
        # x = Conv2D(1280, (2, 2), padding = 'same', activation='relu')(x)
          # x = Dropout(0.25)(x)
  x = BatchNormalization()(x)
  
  x = AveragePooling2D((8, 8))(x)
  x  =  Flatten()(x)
  x = Dropout(0.4)(x)
  x =   Dense(512, activation='relu')(x)
  x  = Dropout(0.25)(x)
  x =    Dense(16)(x)
  outputs = LayerNormalization()(x)
  model = Model(inputs, outputs)

  return model

model2 = model2()

model2.summary()

model1.trainable = False

model = Sequential([model1, model2])

model.summary() #input 299*299*3

type(X_temp)

np.shape(triplet1)

print(model(X_temp[:3])) #output of first triplet
print(model(X_temp[3:6])) #output of second triplet

def triplet_loss(y_true, y_pred):
  img1 = y_pred[:, :16]
  img2 = y_pred[:, 16:32]
  img3 = y_pred[:, 32:48]
  temp1 = tf.square(img1-img2)-tf.square(img1-img3) + 0.2
  temp2 = tf.square(img1-img2)-tf.square(img2-img3) + 0.2

  loss = tf.reduce_sum(tf.maximum(tf.constant(0.), temp1) + tf.maximum(tf.constant(0.), temp2))

  return loss

def training_model():
  img1 = Input((299, 299, 3))
  img2 = Input((299, 299, 3))
  img3 = Input((299, 299, 3))

  img1_emb = model(img1)
  img2_emb = model(img2)
  img3_emb = model(img3)

  outputs = Concatenate(axis = -1)([img1_emb, img2_emb, img3_emb])
  
  model_train = Model(inputs = [img1, img2, img3], outputs = outputs)

  return model_train

model = load_model('/content/drive/MyDrive/facenet model/model1.h5')

model_train = training_model()

model_train.summary()

optimizer = tf.keras.optimizers.Adam(lr = 5e-3)

model_train.compile(optimizer=optimizer, loss = triplet_loss)

np.shape((X_val))

#X_train = np.zeros((1000, 3, 299, 299, 3))

y_train = np.zeros((250, 48))
#y_val = np.zeros((199, 48))

import time

##training loop
j = 0
for i in range(0, 12000, 250): # to cover all triplets
  start_time = time.time()
  X_train = get_triplet(i, i+250)
  model_train.fit([X_train[:, 0],X_train[:, 1],X_train[:, 2]] ,y_train, epochs = 1)
  end_time = time.time()
  print(end_time-start_time, ' secs')

  if i > 12000:
    i = 0
    j += 1
  
  if j == 400:
    break

model.save('/content/drive/MyDrive/facenet model/model1.h5')

